# Speech_Emotion_Detection
The goal of the project Speech Emotion Detection is to automatically identify and categorise the emotions expressed in spoken language. It analyses audio data and extracts pertinent elements for recognising various emotional states using machine learning approach.Â 

## Features

- Preprocessing: Includes techniques for audio signal processing, such as sampling, framing, and windowing, to prepare the speech data for analysis.
- Feature Extraction: Extracts relevant features from speech signals, such as pitch, energy, MFCCs (Mel-Frequency Cepstral Coefficients), and prosodic features,       which capture the emotional content of the speech.
- RNN with LSTM: Utilizes the power of recurrent neural networks with LSTM units to model the sequential nature of speech data and classify emotions.
- Visualization: Provides visualizations of audio features such as wave plot and spectogram to gain insights into the emotional patterns detected in the speech data.

## Dataset link
https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess
